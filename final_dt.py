# -*- coding: utf-8 -*-
"""Final_DT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NzJWbIK5n2jqrNYi74fB7e2JJJGRByqh
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns 
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
import graphviz 
from sklearn.metrics import confusion_matrix
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.svm import LinearSVC
from sklearn.decomposition import PCA

df = pd.read_csv('output.csv')

df.head(5)

df = df.sample(n=200, random_state=1)

X = df[['Games', 'Accuracy_Passes','Shots_Total','Goals_Total','Weight_kg','Height_cm']]

print(X)

print(X.isnull().sum())

print(X.describe())


print(X.info())

df['Rating'] = pd.cut(df['Rating'],bins=[1, 6.5, 7, 10],labels=["Low Rating","Average Rating","High Rating"])

df['Rating'].value_counts()

df['Rating'].unique()

label_mapping = {"Low Rating": 0, "Average Rating": 1, "High Rating": 2}
df = df.replace({"Rating": label_mapping})

df['Rating'].value_counts()

y = df['Rating']


from sklearn.model_selection import train_test_split

X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 42)

print(X_train)

print(y_train)

X_train

X_test

decision_tree = DecisionTreeClassifier(random_state=0, max_depth  = 8 , criterion ='entropy' )
decision_tree = decision_tree.fit(X_train, y_train)

print(decision_tree)

tree.plot_tree(decision_tree)
plt.show()

text_representation = tree.export_text(decision_tree)
print(text_representation)

decision_tree_prediction = decision_tree.predict(X_test)

bn_matrix_R = confusion_matrix(y_test, decision_tree_prediction)
print("\nThe confusion matrix is:")
print(bn_matrix_R)

from sklearn.metrics import classification_report
print(classification_report(y_test, decision_tree_prediction))

fit_accuracy = decision_tree.score(X_train, y_train)
test_accuracy = decision_tree.score(X_test, y_test)
    
print(f"Train accuracy: {fit_accuracy:0.2%}")
print(f"Test accuracy: {test_accuracy:0.2%}")

X

y

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV

# specify the hyperparameters you want to tune
parameters = {
    'criterion': ['gini', 'entropy'],
    'max_depth': range(5,12),
    'min_samples_split': range(1,12),
    'min_samples_leaf': range(1, 12)
}

# create a decision tree classifier
dtc = DecisionTreeClassifier()

# create a grid search object
grid_search = GridSearchCV(dtc, parameters, cv=5)

# fit the grid search object to your data
grid_search.fit(X, y)

# print the best hyperparameters and corresponding accuracy score
print("Best parameters: ", grid_search.best_params_)
print("Best accuracy score: ", grid_search.best_score_)

decision_tree1 = DecisionTreeClassifier(random_state=0, max_depth = 4, min_samples_leaf=1, min_samples_split=3, criterion ='gini' )
decision_tree1 = decision_tree1.fit(X_train, y_train)

decision_tree_prediction1 = decision_tree1.predict(X_test)

bn_matrix_R1 = confusion_matrix(y_test, decision_tree_prediction1)
print("\nThe confusion matrix is:")
print(bn_matrix_R1)

print(classification_report(y_test, decision_tree_prediction1))

fit_accuracy1 = decision_tree1.score(X_train, y_train)
test_accuracy1 = decision_tree1.score(X_test, y_test)
    
print(f"Train accuracy: {fit_accuracy1:0.2%}")
print(f"Test accuracy: {test_accuracy1:0.2%}")

from sklearn.metrics import ConfusionMatrixDisplay
disp = ConfusionMatrixDisplay(confusion_matrix=bn_matrix_R1)
disp.plot()
plt.show()

import graphviz

TREE_data = tree.export_graphviz(decision_tree1, out_file=None,
                  feature_names=X.columns,
                  class_names = ["Low Rating","Average Rating", "High Rating"],
                  filled=True, 
                  rounded=True,  
                  special_characters=True) 
                                   
graph = graphviz.Source(TREE_data) 
graph.render("Tree_Record_small_4")

